{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global new coronavirus progress analysis\n",
    "\n",
    "**Last Update : 2020-01-30 21:30**\n",
    "\n",
    "이 글은 전 세계적으로 퍼지고 있는 신종 코로나 바이러스의 진행 상황을 시각적으로 표현한 자료입니다. 'JHU CSSE'에서 지속적으로 업데이트하고 있는 데이터를 사용하였습니다. 이 분석은 개인적인 연구 목적으로 수행되었으며, 오류가 있을 수 있습니다. 가능한 빨리 모든 국가에서 바이러스가 완전히 사라지기를 진심으로 바랍니다. 감사합니다.\n",
    "\n",
    "This article is a visual representation of the progress of the new coronavirus that is spreading worldwide. I used data that is constantly updated in 'JHU CSSE'. This analysis was conducted for personal research purposes and may be in error. I sincerely hope that the virus will disappear completely in all countries as soon as possible. Thank you.\n",
    "\n",
    "- Data Source  \n",
    "[Dash Board](https://gisanddata.maps.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6)  \n",
    "[Novel Coronavirus (2019-nCoV) Cases, provided by JHU CSSE](https://docs.google.com/spreadsheets/d/1yZv9w9zRKwrGTaR-YzmAqMefw4wMlaXocejdxZaTs6w/htmlview?usp=sharing&sle=true#)\n",
    "\n",
    "\n",
    "- Github Repo  \n",
    "[novel_coronavirus](https://github.com/WooilJeong/novel_coronavirus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load `Novel Coronavirus (2019-nCoV) Cases, provided by JHU CSSE` Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoValidUrlKeyFound",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoValidUrlKeyFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-0a7a2ea86805>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# new sheet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mspreadsheet_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://drive.google.com/file/d/1ZJCEHKijIMVSJvH74C-LIUJb7BAHqj6b/view?ths=true'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_by_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspreadsheet_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\venv\\lib\\site-packages\\gspread\\client.py\u001b[0m in \u001b[0;36mopen_by_url\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \"\"\"\n\u001b[1;32m--> 162\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_by_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextract_id_from_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mopenall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\venv\\lib\\site-packages\\gspread\\utils.py\u001b[0m in \u001b[0;36mextract_id_from_url\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mm1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNoValidUrlKeyFound\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoValidUrlKeyFound\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scope = [\n",
    "'https://spreadsheets.google.com/feeds',\n",
    "'https://www.googleapis.com/auth/drive',\n",
    "]\n",
    "\n",
    "json_file_name = 'gspread-266617-7512230df225.json'\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(json_file_name, scope)\n",
    "\n",
    "gc = gspread.authorize(credentials)\n",
    "# spreadsheet_url = 'https://docs.google.com/spreadsheets/d/1yZv9w9zRKwrGTaR-YzmAqMefw4wMlaXocejdxZaTs6w/htmlview?usp=sharing&sle=true#'\n",
    "# new sheet\n",
    "spreadsheet_url = 'https://drive.google.com/file/d/1ZJCEHKijIMVSJvH74C-LIUJb7BAHqj6b/view?ths=true'\n",
    "doc = gc.open_by_url(spreadsheet_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Dataset Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIError",
     "evalue": "{'code': 400, 'message': 'This operation is not supported for this document', 'status': 'FAILED_PRECONDITION'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-1ab4c1fdd935>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msheet_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworksheets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msheet_nm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msheet_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msheet_nm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sheets number :'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msheet_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\venv\\lib\\site-packages\\gspread\\models.py\u001b[0m in \u001b[0;36mworksheets\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \"\"\"\n\u001b[1;32m--> 238\u001b[1;33m         \u001b[0msheet_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch_sheet_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mWorksheet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'properties'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msheet_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sheets'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\venv\\lib\\site-packages\\gspread\\models.py\u001b[0m in \u001b[0;36mfetch_sheet_metadata\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSPREADSHEET_URL\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\venv\\lib\\site-packages\\gspread\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, endpoint, params, data, json, files, headers)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAPIError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlist_spreadsheet_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAPIError\u001b[0m: {'code': 400, 'message': 'This operation is not supported for this document', 'status': 'FAILED_PRECONDITION'}"
     ]
    }
   ],
   "source": [
    "sheet_list = doc.worksheets()\n",
    "sheet_nm = []\n",
    "for i in sheet_list:\n",
    "    sheet_nm.append(i.title)\n",
    "print('sheets number :', len(sheet_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for i in sheet_nm:\n",
    "    \n",
    "    data = doc.worksheet(i).get_all_values()\n",
    "    globals()[i] = pd.DataFrame(data[1:], columns=data[0])\n",
    "    \n",
    "    df_list.append(globals()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'New Google Sheet Link (support comments): https://drive.google.com/file/d/1ZJCEHKijIMVSJvH74C-LIUJb7BAHqj6b/view?usp=sharing'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Confirmed'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Confirmed'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Confirmed'}\n",
      "{'', 'Quick note: Starting from this tab, our map is updating (almost) in real time (China data - at least once per hour; non China data - several times per day). This table is planning to be updated twice a day. The discrepancy between the map and this sheet is expected. Sorry for any confusion and inconvenience.', 'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Confirmed'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Confirmed'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Confirmed'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Confirmed'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Confirmed'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Confirmed'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Confirmed'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Confirmed'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Confirmed'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Confirmed'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Confirmed'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Confirmed'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Confirmed'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Confirmed'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Confirmed'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Confirmed'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Suspected', 'Confirmed'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Suspected', 'Confirmed'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Suspected', 'Confirmed'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Suspected', 'Confirmed'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Suspected', 'Confirmed'}\n",
      "{'Recovered', 'Deaths', 'Last Update', 'Province/State', 'Country/Region', 'Suspected', 'Confirmed'}\n",
      "{'Demised', 'Recovered', 'Last Update', 'Province/State', 'Country/Region', 'Suspected', 'Confirmed'}\n",
      "{'Country', 'Last Update', 'Province/State', 'Suspected', 'Confirmed'}\n",
      "{'Date last updated', 'Country', 'Province/State', 'Suspected', 'Confirmed'}\n"
     ]
    }
   ],
   "source": [
    "for df in df_list:\n",
    "    print(set(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only use datasets of the same type for analysis\n",
    "\n",
    "- That is, data after 12 PM on January 23  \n",
    "- Based on selecting only datasets that have the following columns in common.\n",
    "\n",
    "```\n",
    "'Province / State',\n",
    "'Country / Region',\n",
    "'Last Update',\n",
    "'Confirmed',\n",
    "'Deaths',\n",
    "'Recovered'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exclude remaining datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_items = ['Jan22_12am','Jan22_12pm','Jan23_12pm']\n",
    "for i in rm_items:\n",
    "    sheet_nm.remove(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common column list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list=[\n",
    "            'Province/State',\n",
    "            'Country/Region',\n",
    "            'Last Update',\n",
    "            'Confirmed',\n",
    "            'Deaths',\n",
    "            'Recovered'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Outliers\n",
    "\n",
    "If the time of the sheet title and 'Last Update' does not match, the value is replaced with the time of the sheet title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sheet_nm:\n",
    "    if len(globals()[i]['Last Update'].unique())>1:        \n",
    "        print(i)\n",
    "        print(\">>>\", globals()[i]['Last Update'].unique(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feb01_11pm['Last Update']='2/1/2020 23:00'\n",
    "Feb01_6pm['Last Update']='2/1/2020 18:00'\n",
    "\n",
    "Jan31_2pm['Last Update']='1/31/2020 14:00'\n",
    "Jan28_11pm['Last Update']='1/28/2020 23:00'\n",
    "Jan25_10pm['Last Update']='1/25/2020 10:00 PM'\n",
    "Jan24_12pm['Last Update']='1/24/2020 12:00 PM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sheet_nm:\n",
    "    if len(globals()[i]['Last Update'].unique())>1:        \n",
    "        print(i)\n",
    "        print(\">>>\", globals()[i]['Last Update'].unique(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in sheet_nm:\n",
    "    \n",
    "    try:\n",
    "        print('Complete :', i)\n",
    "        globals()[i] = globals()[i][col_list]\n",
    "        df = pd.concat([df, globals()[i]])\n",
    "        \n",
    "    except:\n",
    "        print('Failed :', i)\n",
    "\n",
    "df=pd.DataFrame(df,columns=col_list)\n",
    "df.index = range(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check dates and times in different formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df['Last Update'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the dates and times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "date_list=[]\n",
    "for i in df['Last Update']:\n",
    "    \n",
    "    if 'AM' in i:\n",
    "        \n",
    "        a=datetime.datetime.strptime(i, \"%m/%d/%Y %I:%M %p\")\n",
    "        b=datetime.datetime.strftime(a, \"%Y-%m-%d %H:%M\")\n",
    "        \n",
    "    elif 'PM' in i:\n",
    "        \n",
    "        a=datetime.datetime.strptime(i, \"%m/%d/%Y %I:%M %p\")\n",
    "        b=datetime.datetime.strftime(a, \"%Y-%m-%d %H:%M\")        \n",
    "    \n",
    "    else:\n",
    "        \n",
    "        a=datetime.datetime.strptime(i, \"%m/%d/%Y %H:%M\")\n",
    "        b=datetime.datetime.strftime(a, \"%Y-%m-%d %H:%M\")        \n",
    "        \n",
    "    date_list.append(b)\n",
    "\n",
    "date_list\n",
    "\n",
    "df['Last Update'] = date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace spaces with zeros\n",
    "df['Confirmed'] = df[\"Confirmed\"].apply(lambda x: 0 if x==\"\" else x)\n",
    "df['Deaths'] = df[\"Deaths\"].apply(lambda x: 0 if x==\"\" else x)\n",
    "df['Recovered'] = df[\"Recovered\"].apply(lambda x: 0 if x==\"\" else x)\n",
    "df['Province/State'] = df[\"Province/State\"].apply(lambda x: 'None' if x==\"\" else x)\n",
    "\n",
    "# Data type conversion\n",
    "df['Last Update'] = pd.to_datetime(df['Last Update'])\n",
    "df['Confirmed'] = pd.to_numeric(df['Confirmed'])\n",
    "df['Deaths'] = pd.to_numeric(df['Deaths'])\n",
    "df['Recovered'] = pd.to_numeric(df['Recovered'])\n",
    "\n",
    "# Feature Engineering\n",
    "df['D/C'] = (df['Deaths']/df['Confirmed'])*100\n",
    "df['R/C'] = (df['Recovered']/df['Confirmed'])*100\n",
    "\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    os.mkdir('Data')\n",
    "    print('Complete')\n",
    "except:\n",
    "    pass\n",
    "    print('Failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Data/Dataset.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create country-specific data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List of Country/Region\n",
    "# country_list = list(set(df['Country/Region']))\n",
    "# country_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in country_list:\n",
    "#     globals()[i.replace(' ','_')] = df[df['Country/Region']==i]\n",
    "#     globals()[i.replace(' ','_')] = globals()[i.replace(' ','_')].sort_values('Last Update', ascending=True)\n",
    "#     globals()[i.replace(' ','_')].index = range(len(globals()[i.replace(' ','_')]))    \n",
    "#     print(i.replace(' ','_'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "- plot_confirmed() : It shows the trend in the number of confirmed patients.  \n",
    "- plot_deaths_recovered() : It shows the trend in the number of virus deaths and recovered patients.  \n",
    "- plot_dc_rc() : It shows virus death rate and recovery rate.(%)\n",
    "```\n",
    "d/c means Deaths per Confirmed\n",
    "r/c means Recovered per Confirmed\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class corona():\n",
    "    \n",
    "#     def __init__(self, data_nm):\n",
    "        \n",
    "#         # set dataset\n",
    "#         self.data_nm = data_nm\n",
    "#         self.dataset = globals()[self.data_nm].copy()\n",
    "        \n",
    "#         # set date index\n",
    "#         self.dataset.index = self.dataset['Last Update']\n",
    "#         self.dataset.index = self.dataset.index.astype(\"category\")\n",
    "#         self.objects = list(self.dataset.index)\n",
    "#         self.y_pos = np.arange(len(self.objects))        \n",
    "    \n",
    "#     def plot_confirmed(self):\n",
    "\n",
    "#         plt.figure(figsize=(15,5))\n",
    "#         plt.title(self.data_nm+'(Confirmed)', size='25', weight='bold')\n",
    "#         plt.plot(self.y_pos, self.dataset['Confirmed'], color='dodgerblue', linewidth=3, marker='o')\n",
    "#         plt.xticks(self.y_pos, self.objects, rotation=45)\n",
    "#         plt.xlabel('Reported Time', size='20')\n",
    "#         plt.ylabel('Count', size='20')\n",
    "#         plt.show()\n",
    "\n",
    "#     def plot_deaths_recovered(self):\n",
    "        \n",
    "#         plt.figure(figsize=(15,5))\n",
    "#         plt.title(self.data_nm+'(Deaths, Recovered)', size='25', weight='bold')\n",
    "#         plt.plot(self.y_pos, self.dataset['Deaths'], color='tomato', label='Deaths', linewidth=3, marker='o')\n",
    "#         plt.plot(self.y_pos, self.dataset['Recovered'], color='orange', label='Recovered', linewidth=3, marker='o')\n",
    "#         plt.legend(loc='upper left')\n",
    "#         plt.xticks(self.y_pos, self.objects, rotation=45)\n",
    "#         plt.xlabel('Reported Time', size='20')\n",
    "#         plt.ylabel('Count', size='20')\n",
    "#         plt.show()\n",
    "        \n",
    "#     def plot_dc_rc(self):\n",
    "#         plt.figure(figsize=(15,5))\n",
    "#         plt.title(self.data_nm+'(D/C, R/C)', size='25', weight='bold')\n",
    "#         plt.plot(self.y_pos, self.dataset['D/C'], color='tomato', label='D/C', linewidth=3, marker='o')\n",
    "#         plt.plot(self.y_pos, self.dataset['R/C'], color='orange', label='R/C', linewidth=3, marker='o')\n",
    "#         plt.ylim(0, 100)\n",
    "#         plt.legend(loc='upper left')\n",
    "#         plt.xticks(self.y_pos, self.objects, rotation=45)\n",
    "#         plt.xlabel('Reported Time', size='20')\n",
    "#         plt.ylabel('Indicator values(%)', size='20')\n",
    "#         plt.show()\n",
    "        \n",
    "#     def plot_world_confirmed(self):\n",
    "#         plt.figure(figsize=(20,10))\n",
    "#         plt.title('World Confirmed Trend('+self.data_nm+')', size='25', weight='bold')\n",
    "#         for i in self.dataset.columns[1:]:\n",
    "#             plt.plot(self.y_pos, self.dataset[i], label=i, linewidth=3, marker='o')\n",
    "#         plt.legend(loc='upper left')\n",
    "#         plt.xticks(self.y_pos, self.objects, rotation=45)\n",
    "#         plt.xlabel('Reported Time', size='20')\n",
    "#         plt.ylabel('Confirmed Count', size='20')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## World Status Except Some Contries\n",
    "\n",
    "Some countries with specific regional data will be discussed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# world_list=[\n",
    "    \n",
    "#  'South Korea',\n",
    "#  'Japan',\n",
    "#  'Thailand',\n",
    "#  'Singapore',\n",
    "#  'France',\n",
    "#  'Finland',\n",
    "#  'Vietnam',\n",
    "#  'Malaysia',\n",
    "#  'Cambodia',\n",
    "#  'Germany',\n",
    "#  'Ivory Coast',\n",
    "#  'Sri Lanka',\n",
    "#  'United Arab Emirates',\n",
    "#  'Macau',\n",
    "#  'Nepal',\n",
    "#  'Taiwan',\n",
    "#  'Hong Kong'\n",
    "\n",
    "# # 'Mainland China',  \n",
    "# # 'US'\n",
    "# # 'Australia',  \n",
    "# # 'Canada',\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in world_list:\n",
    "#     c = corona(i.replace(' ','_'))\n",
    "#     c.plot_confirmed()\n",
    "#     c.plot_deaths_recovered()\n",
    "#     c.plot_dc_rc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mainland China"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# china_list = list(set(Mainland_China['Province/State']))\n",
    "# for i in china_list:\n",
    "#     globals()[i.replace(' ','_')] = Mainland_China[Mainland_China['Province/State']==i]\n",
    "#     globals()[i.replace(' ','_')] = globals()[i.replace(' ','_')].sort_values('Last Update', ascending=True)\n",
    "#     globals()[i.replace(' ','_')].index = range(len(globals()[i.replace(' ','_')]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in china_list:\n",
    "#     c = corona(i.replace(' ','_'))\n",
    "#     c.plot_confirmed()\n",
    "#     c.plot_deaths_recovered()\n",
    "#     c.plot_dc_rc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# us_list = list(set(US['Province/State']))\n",
    "# for i in us_list:\n",
    "#     globals()[i.replace(' ','_')] = US[US['Province/State']==i]\n",
    "#     globals()[i.replace(' ','_')] = globals()[i.replace(' ','_')].sort_values('Last Update', ascending=True)\n",
    "#     globals()[i.replace(' ','_')].index = range(len(globals()[i.replace(' ','_')]))    \n",
    "#     print(i.replace(' ','_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in us_list:\n",
    "#     c = corona(i.replace(' ','_'))\n",
    "#     c.plot_confirmed()\n",
    "#     c.plot_deaths_recovered()\n",
    "#     c.plot_dc_rc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Australia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# australia_list = list(set(Australia['Province/State']))\n",
    "# for i in australia_list:\n",
    "#     globals()[i.replace(' ','_')] = Australia[Australia['Province/State']==i]\n",
    "#     globals()[i.replace(' ','_')] = globals()[i.replace(' ','_')].sort_values('Last Update', ascending=True)\n",
    "#     globals()[i.replace(' ','_')].index = range(len(globals()[i.replace(' ','_')]))    \n",
    "#     print(i.replace(' ','_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in australia_list:\n",
    "#     c = corona(i.replace(' ','_'))\n",
    "#     c.plot_confirmed()\n",
    "#     c.plot_deaths_recovered()\n",
    "#     c.plot_dc_rc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canada\n",
    "\n",
    "- Canada has very inaccurate information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# canada_list = list(set(Canada['Province/State']))\n",
    "# for i in canada_list:\n",
    "#     globals()[i.replace(' ','_')] = Canada[Canada['Province/State']==i]\n",
    "#     globals()[i.replace(' ','_')] = globals()[i.replace(' ','_')].sort_values('Last Update', ascending=True)\n",
    "#     globals()[i.replace(' ','_')].index = range(len(globals()[i.replace(' ','_')]))    \n",
    "#     print(i.replace(' ','_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in canada_list:\n",
    "#     c = corona(i.replace(' ','_'))\n",
    "#     c.plot_confirmed()\n",
    "#     c.plot_deaths_recovered()\n",
    "#     c.plot_dc_rc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Number of Confirmation by Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_list = list(set(df['Last Update']))\n",
    "# time_list = pd.DataFrame(time_list, columns=['Last Update']).sort_values('Last Update')\n",
    "# time_list.index = range(len(time_list))\n",
    "\n",
    "# total_list=world_list+china_list+us_list+australia_list+canada_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in total_list:\n",
    "#     i=i.replace(' ','_')\n",
    "#     time_list=pd.merge(time_list, globals()[i][['Last Update', 'Confirmed']], how='left', on='Last Update')\n",
    "# time_list.columns=['Last Update']+total_list\n",
    "# time_list=time_list.fillna(0)\n",
    "# time_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_china = time_list[['Last Update']+china_list]\n",
    "# china_list2 = china_list.copy()\n",
    "# china_list2.remove('Hubei')\n",
    "# df_china2 = time_list[['Last Update']+china_list2]\n",
    "# df_world = time_list[['Last Update']+world_list]\n",
    "# df_us = time_list[['Last Update']+us_list]\n",
    "# df_australia = time_list[['Last Update']+australia_list]\n",
    "# df_canada = time_list[['Last Update']+canada_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## China"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# c = corona('df_china')\n",
    "# c.plot_world_confirmed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## China without Hubei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# c = corona('df_china2')\n",
    "# c.plot_world_confirmed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# c = corona('df_world')\n",
    "# c.plot_world_confirmed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# c = corona('df_us')\n",
    "# c.plot_world_confirmed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Australia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# c = corona('df_australia')\n",
    "# c.plot_world_confirmed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# c = corona('df_canada')\n",
    "# c.plot_world_confirmed()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
